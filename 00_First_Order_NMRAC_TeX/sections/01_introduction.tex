\section{Introduction}
Model reference control is a technique that imposes a behavior on a system, by equating the the output of the model reference with the output of the controlled system. This way, the gains of a pre-defined controller structure can be found. 

However, this only works if the system's dynamics are known exactly, which is often far from reality. If the system's dynamics are not fully known, the controller gains can be found adaptively by a technique called \textit{model reference adaptive control} (MRAC). The adaptation law can be chosen in two ways, firstly a gradient descent-based update law as first proposed by Whitaker et al. \cite{whitaker1959adaptive} and applied in for example \cite{wahby, bosshartComparisonTwoPID2021}, and secondly, a Lyapunov-based update law as proposed by Shackcloth et al. \cite{shackclothSynthesisModelReference1965}. The latter enforces that in every update step, we have a stabilizing controller, which is not guaranteed when using the former. In this work, we make use of a Lyapunov-based update law, to guarantee stability during the learning process.

Neural networks are ideal candidate functions for control laws, since they can be considered to be universal approximators \cite{hornikUniversalApproximationUnknown1990a}. Since at least the 90s, research has been conducted on NN controllers \cite{jiangBriefReviewNeural2017}, and it has been shown that they can learn a desired behavior, for example in \cite{wahby, congPIDLikeNeuralNetwork2009,thanhNonlinearPIDControl2006,norrisNeuralNetworksControl2021}. However, standard NNs are nonlinear, through the use of nonlinear activation functions, which makes their the formal verification of challenging. They often rely on post-training stability verification, as done in \cite{kordaStabilityPerformanceVerification2022, revay_convex_2021}, which does not support any type of online learning for imporivng the control strategy, while guaranteeing a stabilizing contoller.

The algorithm, proposed in this paper, is derived from a Lyapunov-based, linear MRAC, as for example in \cite{lavretskyCombinedCompositeModel2009, slamaModelReferenceAdaptive2018,astromAdaptiveControl2008}, which defines a stable learning strategy for first-order systems controlled by NNs.